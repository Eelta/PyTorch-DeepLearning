[1mdiff --git "a/\346\267\261\345\272\246\345\255\246\344\271\240.md" "b/\346\267\261\345\272\246\345\255\246\344\271\240.md"[m
[1mindex f37bff4..7b7f097 100644[m
[1m--- "a/\346\267\261\345\272\246\345\255\246\344\271\240.md"[m
[1m+++ "b/\346\267\261\345\272\246\345\255\246\344\271\240.md"[m
[36m@@ -26,7 +26,7 @@[m [mXï¼šå·¦æ¨ªå³ç«–ï¼ˆç»´åº¦nï¼‰ï¼›Yï¼šæœå‘ä¸Xç›¸åŒï¼ˆç»´åº¦mï¼‰ã€‚[m
 [m
 2ã€‚å°†é¢„æµ‹å€¼é›†åˆä¸çœŸå®å€¼é›†åˆè®¡ç®—è·å–å•ä¸ªæƒé‡ä¸‹çš„è¯¯å·®ã€‚[m
 [m
[31m-3ã€‚å¯¹æƒé‡æ›´æ–°ï¼Œä½¿å¾—å¯¹åº”è¯¯å·®æœ€å°ã€‚[m
[32m+[m[32m3ã€‚å¯¹æƒé‡æ›´æ–°ï¼Œä½¿å¾—å¯¹åº”è¯¯å·®æœ€å°ã€‚[m[41m [m
 [m
 ## æ¢¯åº¦ä¸‹é™[m
 [m
[36m@@ -68,7 +68,7 @@[m [mWæ›´æ–°ï¼šW=W-Î±Lâ€˜ï¼Œè¿™é‡ŒÎ±æ˜¯å­¦ä¹ ç‡ï¼Œå³æ¯æ¬¡å‘æœ€ä½ç‚¹ç§»åŠ¨çš„æ­¥[m
 [m
 <img src="ç¬”è®°å›¾ä¿å­˜\2cd40aba1e9f50bbb868d767a113cb41.png" alt="2cd40aba1e9f50bbb868d767a113cb41" style="zoom: 33%;" />[m
 [m
[31m-é—®é¢˜ï¼šå¦‚æœæ¯æ¬¡éƒ½ç±»ä¼¼ä¸Šé¢è¿›è¡Œè®¡ç®—ï¼Œå‡½æ•°å±•å¼€åå½¢å¼å°†å§‹ç»ˆä¸å˜åŒ–ï¼Œå˜æ¢å¤±å»æ„ä¹‰ã€‚ä¸ºæ­¤ï¼Œåœ¨æ¯æ¬¡ç»“æœè¾“å‡ºæ—¶éœ€è¦å¯¹ç»“æœå‘é‡åšä¸€ä¸ªéçº¿æ€§å‡½æ•°çš„å˜æ¢ï¼ˆå³æ¿€æ´»å‡½æ•°ï¼‰ã€‚[m
[32m+[m[32mé—®é¢˜ï¼šå¦‚æœæ¯æ¬¡éƒ½ç±»ä¼¼ä¸Šé¢è¿›è¡Œè®¡ç®—ï¼Œå‡½æ•°å±•å¼€åå½¢å¼å°†å§‹ç»ˆä¸å˜åŒ–ï¼Œå˜æ¢å¤±å»æ„ä¹‰ã€‚ä¸ºæ­¤ï¼Œåœ¨æ¯æ¬¡ç»“æœè¾“å‡ºæ—¶éœ€è¦å¯¹ç»“æœå‘é‡åšä¸€ä¸ª**éçº¿æ€§å‡½æ•°çš„å˜æ¢**ï¼ˆå³**æ¿€æ´»å‡½æ•°**ï¼‰ã€‚[m
 [m
 <img src="ç¬”è®°å›¾ä¿å­˜\fa7ae0ef402295b7136744f5146b4dd5.png" alt="fa7ae0ef402295b7136744f5146b4dd5" style="zoom: 33%;" />[m
 [m
[36m@@ -296,7 +296,6 @@[m [mLogisticå›å½’æ˜¯é’ˆå¯¹äºŒåˆ†ç±»é—®é¢˜çš„ã€‚[m
 2. L1ã€L2æ­£åˆ™åŒ–ï¼Œé˜²æ­¢WçŸ©é˜µè°ƒèŠ‚ç¨‹åº¦è¿‡å¤§ã€‚[m
 3. ä½¿ç”¨å…¶å®ƒæ¿€æ´»å‡½æ•°ã€‚[m
 [m
[31m-[m
 <img src="ç¬”è®°å›¾ä¿å­˜\7ed7aefe0d4cd592c66aea4fc7bc0bf0.png" alt="7ed7aefe0d4cd592c66aea4fc7bc0bf0" style="zoom: 33%;" />[m
 [m
 å¸¸è§çš„Sigmodå‡½æ•°ï¼š[m
[36m@@ -358,7 +357,7 @@[m [mfor epoch in range(1000):[m
 # é’ˆå¯¹ä¸åŒçš„xç”Ÿæˆé¢„æµ‹å€¼å¹¶å±•ç¤º[m
 x = np.linspace(0, 10, 200)[m
 # reshapeæ“ä½œ[m
[31m-x_t = torch.Tensor(x).view((200, 1))[m
[32m+[m[32mx_t = torch.Tensor(x).view((200, 1))[m[41m  [m
 y_t = model(x_t)[m
 y = y_t.data.numpy()[m
 plt.plot(x, y)[m
[36m@@ -381,7 +380,7 @@[m [mplt.show()[m
 [m
 å‡è®¾éœ€è¦æŒ‰ç…§ä¸Šé¢çš„æ–¹å¼è¿›è¡Œè°ƒæ•´ï¼Œåªéœ€ä¿®æ”¹æ­¤å¤„æ¨¡å‹çš„è¾“å…¥ç»´æ•°å³å¯ã€‚ [m
 [m
[31m-ä¸ºä»€ä¹ˆæœ‰æ—¶ä¼šè°ƒæ•´è¾“å‡ºç»´åº¦ï¼š[m
[32m+[m[32mä¸ºä»€ä¹ˆéœ€è¦è°ƒæ•´è¾“å‡ºç»´åº¦ï¼š[m
 [m
 å¯ä»¥çœ‹ä½œï¼Œè¿™é‡Œåªæ˜¯è°ƒæ•´ä¸­é—´æ­¥éª¤è¾“å‡ºçš„ç»´åº¦ï¼Œéœ€è¦åœ¨è¿›è¡Œå¤šæ¬¡å˜æ¢åï¼Œæœ€åå†æ¬¡è½¬æ¢ä¸ºä¸€ç»´è¾“å‡ºç»“æœã€‚[m
 [m
[36m@@ -687,7 +686,7 @@[m [mprint("=" * 30)[m
 [m
 2.è¾“å‡ºçš„å’Œç­‰äº1ï¼Œ[m
 [m
[31m-è§£å†³æ–¹æ¡ˆï¼šç¥ç»ç½‘ç»œä¿æŒå…ˆå‰çš„sigmodå±‚ä¸å˜ï¼Œè¾“å‡ºå±‚ä½¿ç”¨softmaxã€‚[m
[32m+[m[32mè§£å†³æ–¹æ¡ˆï¼šç¥ç»ç½‘ç»œä¿æŒå…ˆå‰çš„æ¿€æ´»å‡½æ•°ä¸å˜ï¼Œè¾“å‡ºå±‚ä½¿ç”¨softmaxã€‚[m
 [m
 è¿™é‡Œï¼Œç›´æ¥æ§åˆ¶è¾“å‡ºçš„é¢„æµ‹å€¼y_preç»´æ•°ä¸ºæ ·æœ¬ç±»åˆ«æ•°ï¼š[m
 [m
[36m@@ -746,7 +745,7 @@[m [mprint("Loss1 = ", l1.data, "\nLoss2 = ", l2.data)[m
 [m
 æ¯å¼ å›¾åƒéƒ½å¯ä»¥çœ‹ä½œçŸ©é˜µå½¢å¼ï¼Œä½¿ç”¨8ä½ï¼ˆ1å­—èŠ‚ï¼‰æ¥è¡¨ç¤ºæ¯ä¸ªåƒç´ çš„ç°åº¦å€¼ï¼Œ8ä½å¯ä»¥è¡¨ç¤ºçš„æ•´æ•°èŒƒå›´æ˜¯0åˆ°255ï¼ˆ2^8=256ï¼‰ã€‚[m
 [m
[31m-å°†ï¼ˆ0-255ï¼‰è¿›è¡Œæ ‡å‡†åŒ–ï¼Œåˆ™å¯ä»¥æ„æˆæ•°æ®é›†çŸ©é˜µã€‚ä¾‹å¦‚ä¸‹å›¾æ˜¯ï¼ˆ1ï¼Œ28ï¼Œ28ï¼‰ï¼ˆC(channel)ï¼ŒW(width)ï¼ŒH(height)ï¼‰ã€‚[m
[32m+[m[32må°†ï¼ˆ0-255ï¼‰è¿›è¡Œæ ‡å‡†åŒ–ï¼Œåˆ™å¯ä»¥æ„æˆæ•°æ®é›†çŸ©é˜µã€‚ä¾‹å¦‚ä¸‹å›¾æ˜¯ï¼ˆ1ï¼Œ28ï¼Œ28ï¼‰ï¼ˆC(channel)ï¼ŒH(height)ï¼ŒW(width)ï¼‰ã€‚[m
 [m
 channelæŒ‡é¢œè‰²é€šé“ï¼ŒRGBé€šé“æ•°ä¸º3ï¼Œæ­¤å¤„é»‘ç™½åˆ™ä¸º1ã€‚[m
 [m
[36m@@ -762,7 +761,7 @@[m [mimport torch.nn.functional as F[m
 # è®¾ç½®æ‰¹é‡å¤„ç†çš„æ ·æœ¬æ•°=64[m
 batch_size = 64[m
 # æ„é€ å¯¹å›¾åƒè¿›è¡Œå¤„ç†çš„è½¬æ¢å™¨transformï¼Œå¯¹æ¯ä¸ªå…ƒç´ è¿›è¡Œè¿›è¡Œpiplineå¤„ç†ï¼š[m
[31m-# é¦–å…ˆå°†æ¯å¼ å›¾ç‰‡è½¬æ¢ä¸ºï¼ˆCï¼ŒWï¼ŒHï¼‰çš„Tensorå½¢å¼ï¼Œtransforms.ToTensor() ä¼šæŠŠå›¾åƒåƒç´ ä» [0, 255] ç¼©æ”¾åˆ° [0.0, 1.0][m
[32m+[m[32m# é¦–å…ˆå°†æ¯å¼ å›¾ç‰‡è½¬æ¢ä¸ºï¼ˆCï¼ŒHï¼ŒWï¼‰çš„Tensorå½¢å¼ï¼Œtransforms.ToTensor() ä¼šæŠŠå›¾åƒåƒç´ ä» [0, 255] ç¼©æ”¾åˆ° [0.0, 1.0][m
 # ç„¶åå°†æ¯ä¸ªTensorè¿›è¡Œæ ‡å‡†åŒ–ç¼©æ”¾ï¼Œæ­¤å¤„ç¼©æ”¾è‡³å‡å€¼0.1307ï¼Œæ ‡å‡†å·®0.3081çš„æ­£æ€åˆ†å¸ƒï¼ˆMNISTæ•°æ®é›†å›¾åƒçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼‰ã€‚[m
 transform = transforms.Compose([transforms.ToTensor(),[m
                                 transforms.Normalize((0.1307,), (0.3081,))[m
[36m@@ -1487,6 +1486,18 @@[m [mAUC < 0.5ï¼šè¡¨ç¤ºæ¨¡å‹æ€§èƒ½ä¸å¦‚éšæœºçŒœæµ‹ã€‚[m
 æ³¨ï¼šAUCåªèƒ½ç”¨äºäºŒåˆ†ç±»é—®é¢˜[m
 ```[m
 [m
[32m+[m[32m## ç½®ä¿¡åŒºé—´[m
[32m+[m
[32m+[m[32mç½®ä¿¡åŒºé—´æ˜¯å¯¹â€œçœŸå®æ€§èƒ½å€¼å¯èƒ½è½åœ¨å“ªä¸ªèŒƒå›´â€çš„ä¸€ä¸ªç»Ÿè®¡ä¼°è®¡ã€‚ç”±äºåªåœ¨**æœ‰é™æ ·æœ¬**ï¼ˆå¦‚ 100 æ¡æµ‹è¯•æ•°æ®ï¼‰ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œå¾—åˆ°çš„å‡†ç¡®ç‡ï¼ˆå¦‚ 93%ï¼‰åªæ˜¯ä¸€ä¸ª**ç‚¹ä¼°è®¡**ï¼Œå®ƒå¯èƒ½å› ä¸ºæ ·æœ¬éšæœºæ€§è€Œåç¦»çœŸå®å€¼ã€‚ç½®ä¿¡åŒºé—´ç»™å‡ºäº†ä¸€ä¸ªèŒƒå›´ï¼ˆä¾‹å¦‚ [90.6%, 94.1%]ï¼‰ï¼Œè¡¨ç¤ºï¼š**å¦‚é‡å¤å¤šæ¬¡ä»åŒä¸€åˆ†å¸ƒä¸­æŠ½æ ·è¯„ä¼°ï¼Œå¤§çº¦ 95% çš„åŒºé—´ä¼šåŒ…å«çœŸå®å‡†ç¡®ç‡**ã€‚[m
[32m+[m
[32m+[m[32mHugging Face çš„ `bootstrap` é»˜è®¤ä½¿ç”¨ **95% ç½®ä¿¡æ°´å¹³**ã€‚[m[41m [m
[32m+[m
[32m+[m[32m<img src="ç¬”è®°å›¾ä¿å­˜/96e57d74-a89b-44e6-91c3-edf329c74da1.png" alt="96e57d74-a89b-44e6-91c3-edf329c74da1" style="zoom: 67%;" />[m
[32m+[m
[32m+[m[32må³ï¼šâ€œæœ‰ 95% çš„æŠŠæ¡è®¤ä¸ºï¼šè¿™ä¸ªæ¨¡å‹åœ¨â€œæ•´ä¸ªæµ‹è¯•æ•°æ®æ€»ä½“â€ä¸Šçš„çœŸå®å‡†ç¡®ç‡ï¼Œè½åœ¨ 90.6% åˆ° 94.1% ä¹‹é—´ã€‚â€[m
[32m+[m
[32m+[m[32m<img src="ç¬”è®°å›¾ä¿å­˜/09ca2bc3-3578-49d7-ae54-a7a14e48167e.png" alt="09ca2bc3-3578-49d7-ae54-a7a14e48167e" style="zoom:67%;" />[m
[32m+[m
 ## æ˜¾å­˜å ç”¨è®¡ç®—[m
 [m
 æ˜¾å­˜ â‰ˆ å‚æ•°é‡ Ã— å­˜æ”¾å‚æ•°å¯¹åº”çš„å­—èŠ‚[m
[36m@@ -4070,285 +4081,6 @@[m [mAnchorå’ŒNegativeï¼šä¸åŒäºº[m
 [m
 è¿™é‡Œä»…é€‰æ‹©ä¸€ä¸ªä¸­é—´å±‚è¾“å‡ºè¿›è¡Œé£æ ¼ä»£ä»·å‡½æ•°è®¡ç®—ï¼Œä½†å®é™…ä¸Šå¯è‡ªé€‰å¤šä¸ªï¼ˆå¦‚ä¸åŒçš„æ—©æœŸå±‚ã€æ™šæœŸå±‚ä»¥å®ç°é£æ ¼æ§åˆ¶ï¼‰ï¼ˆåŒæ­¥è®¾ç½®å¤šä¸ªæƒé‡å‚æ•°ï¼‰ï¼Œä½¿ç»“æœæ›´ä¼˜ã€‚[m
 [m
[31m-## è§†è§‰Promptå·¥ç¨‹[m
[31m-[m
[31m-ä»»ä½•å½¢å¼çš„å†…å®¹éƒ½å¯ä»¥ä½œä¸ºPromptï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ç­‰[m
[31m-[m
[31m-<img src="ç¬”è®°å›¾ä¿å­˜/PixPin_2025-10-16_19-33-14.png" alt="PixPin_2025-10-16_19-33-14" style="zoom:50%;" />[m
[31m-[m
[31m-å½“æåŠInputï¼Œå®ƒå¾€å¾€åŒ…å«äº†Prompt[m
[31m-[m
[31m-<img src="ç¬”è®°å›¾ä¿å­˜/PixPin_2025-10-16_19-42-43.png" alt="PixPin_2025-10-16_19-42-43" style="zoom: 33%;" />[m
[31m-[m
[31m-å’Œæ³¨é‡è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æµç¨‹ä¸åŒï¼ŒPromptå·¥ç¨‹å¾€å¾€åŸºäºé¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿›è¡Œæ¨¡å‹è®¾ç½®ã€è¾“å…¥å’Œæç¤ºä¿®æ”¹ï¼Œä¸ä¼šè¿›è¡Œä»»ä½•æ¨¡å‹æƒé‡ä¿®æ”¹[m
[31m-[m
[31m-<img src="ç¬”è®°å›¾ä¿å­˜/PixPin_2025-10-16_19-44-07.png" alt="PixPin_2025-10-16_19-44-07" style="zoom:33%;" />[m
[31m-[m
[31m-### åˆ†å‰²[m
[31m-[m
[31m-```python[m
[31m-[m
[31m-```[m
[31m-[m
[31m-utils.py[m
[31m-[m
[31m-```[m
[31m-import matplotlib.pyplot as plt[m
[31m-import numpy as np[m
[31m-import random[m
[31m-from PIL import Image[m
[31m-import torch[m
[31m-[m
[31m-[m
[31m-def resize_image(image, input_size):[m
[31m-    w, h = image.size[m
[31m-    scale = input_size / max(w, h)[m
[31m-    new_w = int(w * scale)[m
[31m-    new_h = int(h * scale)[m
[31m-    image = image.resize((new_w, new_h))[m
[31m-    return image[m
[31m-[m
[31m-def format_results(result, filter=0):[m
[31m-    annotations = [][m
[31m-    n = len(result.masks.data)[m
[31m-    for i in range(n):[m
[31m-        annotation = {}[m
[31m-        mask = result.masks.data[i] == 1.0[m
[31m-[m
[31m-        if torch.sum(mask) < filter:[m
[31m-            continue[m
[31m-        annotation["id"] = i[m
[31m-        annotation["segmentation"] = mask.cpu().numpy()[m
[31m-        annotation["bbox"] = result.boxes.data[i][m
[31m-        annotation["score"] = result.boxes.conf[i][m
[31m-        annotation["area"] = annotation["segmentation"].sum()[m
[31m-        annotations.append(annotation)[m
[31m-    return annotations[m
[31m-[m
[31m-[m
[31m-def box_prompt(masks, bbox):[m
[31m-    h = masks.shape[1][m
[31m-    w = masks.shape[2][m
[31m-    [m
[31m-    bbox[0] = round(bbox[0]) if round(bbox[0]) > 0 else 0[m
[31m-    bbox[1] = round(bbox[1]) if round(bbox[1]) > 0 else 0[m
[31m-    bbox[2] = round(bbox[2]) if round(bbox[2]) < w else w[m
[31m-    bbox[3] = round(bbox[3]) if round(bbox[3]) < h else h[m
[31m-[m
[31m-    # IoUs = torch.zeros(len(masks), dtype=torch.float32)[m
[31m-    bbox_area = (bbox[3] - bbox[1]) * (bbox[2] - bbox[0])[m
[31m-[m
[31m-    masks_area = torch.sum(masks[:, bbox[1] : bbox[3], bbox[0] : bbox[2]], dim=(1, 2))[m
[31m-    orig_masks_area = torch.sum(masks, dim=(1, 2))[m
[31m-[m
[31m-    union = bbox_area + orig_masks_area - masks_area[m
[31m-    IoUs = masks_area / union[m
[31m-    max_iou_index = torch.argmax(IoUs)[m
[31m-[m
[31m-    return masks[max_iou_index].cpu().numpy(), max_iou_index[m
[31m-[m
[31m-[m
[31m-[m
[31m-def point_prompt(masks, points, point_label):  # numpy å¤„ç†[m
[31m-    h = masks[0]["segmentation"].shape[0][m
[31m-    w = masks[0]["segmentation"].shape[1][m
[31m-    [m
[31m-    onemask = np.zeros((h, w))[m
[31m-    masks = sorted(masks, key=lambda x: x['area'], reverse=True)[m
[31m-    for i, annotation in enumerate(masks):[m
[31m-        if type(annotation) == dict:[m
[31m-            mask = annotation['segmentation'][m
[31m-        else:[m
[31m-            mask = annotation[m
[31m-        for i, point in enumerate(points):[m
[31m-            if mask[point[1], point[0]] == 1 and point_label[i] == 1:[m
[31m-                onemask[mask] = 1[m
[31m-            if mask[point[1], point[0]] == 1 and point_label[i] == 0:[m
[31m-                onemask[mask] = 0[m
[31m-    onemask = onemask >= 1[m
[31m-    return onemask, 0[m
[31m-[m
[31m-[m
[31m-def show_masks_on_image(image, masks):[m
[31m-    # Create a mask image (assuming binary mask)[m
[31m-    #image_with_mask = Image.open(image_path).convert("RGBA")[m
[31m-    image_with_mask = image.convert("RGBA")[m
[31m-    [m
[31m-    for mask in masks:[m
[31m-        #mask = mask.cpu().numpy()[m
[31m-        [m
[31m-        height, width = mask.shape[m
[31m-        mask_array = np.zeros((height, width, 4), dtype=np.uint8)[m
[31m-        color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255), 150][m
[31m-        [m
[31m-        mask_array[mask, :] = color[m
[31m-        mask_image = Image.fromarray(mask_array)[m
[31m-[m
[31m-        width, height = image_with_mask.size[m
[31m-        mask_image = mask_image.resize((width, height))[m
[31m-        [m
[31m-        # Overlay the mask on the image[m
[31m-        image_with_mask = Image.alpha_composite([m
[31m-            image_with_mask,[m
[31m-            mask_image)[m
[31m-    [m
[31m-    # Display the result[m
[31m-    image_with_mask.show()[m
[31m-[m
[31m-[m
[31m-def show_box(box, ax):[m
[31m-    x0, y0 = box[0], box[1][m
[31m-    w, h = box[2] - box[0], box[3] - box[1][m
[31m-    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))[m
[31m-[m
[31m-def show_boxes_on_image(raw_image, boxes):[m
[31m-    plt.figure(figsize=(10,10))[m
[31m-    plt.imshow(raw_image)[m
[31m-    for box in boxes:[m
[31m-      show_box(box, plt.gca())[m
[31m-    plt.axis('on')[m
[31m-    plt.show()[m
[31m-[m
[31m-[m
[31m-def show_points_on_image(raw_image, input_points, input_labels=None):[m
[31m-    plt.figure(figsize=(10,10))[m
[31m-    plt.imshow(raw_image)[m
[31m-    input_points = np.array(input_points)[m
[31m-    if input_labels is None:[m
[31m-      labels = np.ones_like(input_points[:, 0])[m
[31m-    else:[m
[31m-      labels = np.array(input_labels)[m
[31m-    show_points(input_points, labels, plt.gca())[m
[31m-    plt.axis('on')[m
[31m-    plt.show()[m
[31m-[m
[31m-import matplotlib.pyplot as plt[m
[31m-import numpy as np[m
[31m-[m
[31m-def show_mask(mask, ax, random_color=False):[m
[31m-    if random_color:[m
[31m-        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)[m
[31m-    else:[m
[31m-        color = np.array([30/255, 144/255, 255/255, 0.6])[m
[31m-    h, w = mask.shape[-2:][m
[31m-    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)[m
[31m-    ax.imshow(mask_image)[m
[31m-[m
[31m-[m
[31m-def show_box(box, ax):[m
[31m-    x0, y0 = box[0], box[1][m
[31m-    w, h = box[2] - box[0], box[3] - box[1][m
[31m-    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))[m
[31m-[m
[31m-def show_boxes_on_image(raw_image, boxes):[m
[31m-    plt.figure(figsize=(10,10))[m
[31m-    plt.imshow(raw_image)[m
[31m-    for box in boxes:[m
[31m-      show_box(box, plt.gca())[m
[31m-    plt.axis('on')[m
[31m-    plt.show()[m
[31m-[m
[31m-def show_points_on_image(raw_image, input_points, input_labels=None):[m
[31m-    plt.figure(figsize=(10,10))[m
[31m-    plt.imshow(raw_image)[m
[31m-    input_points = np.array(input_points)[m
[31m-    if input_labels is None:[m
[31m-      labels = np.ones_like(input_points[:, 0])[m
[31m-    else:[m
[31m-      labels = np.array(input_labels)[m
[31m-    show_points(input_points, labels, plt.gca())[m
[31m-    plt.axis('on')[m
[31m-    plt.show()[m
[31m-[m
[31m-def show_points_and_boxes_on_image(raw_image, boxes, input_points, input_labels=None):[m
[31m-    plt.figure(figsize=(10,10))[m
[31m-    plt.imshow(raw_image)[m
[31m-    input_points = np.array(input_points)[m
[31m-    if input_labels is None:[m
[31m-      labels = np.ones_like(input_points[:, 0])[m
[31m-    else:[m
[31m-      labels = np.array(input_labels)[m
[31m-    show_points(input_points, labels, plt.gca())[m
[31m-    for box in boxes:[m
[31m-      show_box(box, plt.gca())[m
[31m-    plt.axis('on')[m
[31m-    plt.show()[m
[31m-[m
[31m-def show_points_and_boxes_on_image(raw_image, boxes, input_points, input_labels=None):[m
[31m-    plt.figure(figsize=(10,10))[m
[31m-    plt.imshow(raw_image)[m
[31m-    input_points = np.array(input_points)[m
[31m-    if input_labels is None:[m
[31m-      labels = np.ones_like(input_points[:, 0])[m
[31m-    else:[m
[31m-      labels = np.array(input_labels)[m
[31m-    show_points(input_points, labels, plt.gca())[m
[31m-    for box in boxes:[m
[31m-      show_box(box, plt.gca())[m
[31m-    plt.axis('on')[m
[31m-    plt.show()[m
[31m-[m
[31m-def show_points(coords, labels, ax, marker_size=375):[m
[31m-    pos_points = coords[labels==1][m
[31m-    neg_points = coords[labels==0][m
[31m-    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)[m
[31m-    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)[m
[31m-[m
[31m-def show_masks_on_image(image, masks):[m
[31m-    # Create a mask image (assuming binary mask)[m
[31m-    #image_with_mask = Image.open(image_path).convert("RGBA")[m
[31m-    image_with_mask = image.convert("RGBA")[m
[31m-    [m
[31m-    for mask in masks:[m
[31m-        #mask = mask.cpu().numpy()[m
[31m-        [m
[31m-        height, width = mask.shape[m
[31m-        mask_array = np.zeros((height, width, 4), dtype=np.uint8)[m
[31m-        color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255), 150][m
[31m-        [m
[31m-        mask_array[mask, :] = color[m
[31m-        mask_image = Image.fromarray(mask_array)[m
[31m-[m
[31m-        width, height = image_with_mask.size[m
[31m-        mask_image = mask_image.resize((width, height))[m
[31m-        [m
[31m-        # Overlay the mask on the image[m
[31m-        image_with_mask = Image.alpha_composite([m
[31m-            image_with_mask,[m
[31m-            mask_image)[m
[31m-    [m
[31m-    # Display the result[m
[31m-    return image_with_mask[m
[31m-[m
[31m-def show_binary_mask(masks, scores):[m
[31m-    if len(masks.shape) == 4:[m
[31m-      masks = masks.squeeze()[m
[31m-    if scores.shape[0] == 1:[m
[31m-      scores = scores.squeeze()[m
[31m-[m
[31m-    fig, ax = plt.subplots(figsize=(15, 15))[m
[31m-    idx = scores.tolist().index(max(scores))[m
[31m-    mask = masks[idx].cpu().detach()[m
[31m-    ax.imshow(np.array(masks[0,:,:]), cmap='gray')[m
[31m-    score = scores[idx][m
[31m-    ax.title.set_text(f"Score: {score.item():.3f}")[m
[31m-    ax.axis("off")[m
[31m-    plt.show()[m
[31m-[m
[31m-```[m
[31m-[m
[31m-### æ£€æµ‹[m
[31m-[m
[31m-[m
[31m-[m
[31m-### ç”Ÿæˆ[m
[31m-[m
[31m-[m
[31m-[m
[31m-### å¾®è°ƒ[m
[31m-[m
[31m-[m
[31m-[m
 # å¤šæ¨¡æ€ï¼ˆå¾…æ›´æ–°ï¼‰[m
 [m
 ## CLIPï¼ˆå¾…æ›´æ–°ï¼‰[m
[36m@@ -7192,7 +6924,306 @@[m [mfor i in range(len(labels)):[m
 [m
 ```[m
 [m
[31m-## å…¶ä»–åŠŸèƒ½ï¼ˆå¾…æ›´æ–°ï¼‰[m
[32m+[m[32m## å…¶ä»–åŠŸèƒ½[m
[32m+[m
[32m+[m[32m### Trainerï¼ˆå¾…æ›´æ–°ï¼‰[m
[32m+[m
[32m+[m[32mHugging Face Transformers Trainer çš„ä¸»è¦åŠŸèƒ½ï¼š[m
[32m+[m
[32m+[m[32m1. **æ•°æ®å¤„ç†**ï¼šåŠ è½½æ•°æ®é›†ï¼Œä¾‹å¦‚å¯è¿›è¡Œåˆ†è¯å’ŒåŠ¨æ€å¡«å……[m
[32m+[m
[32m+[m[32m2. **æ¨¡å‹åˆå§‹åŒ–**ï¼šä½¿ç”¨ model_init å‡½æ•°æ”¯æŒè¶…å‚æ•°æœç´¢æ—¶çš„æ¨¡å‹é‡æ–°åˆå§‹åŒ–[m
[32m+[m
[32m+[m[32m3. **è¯„ä¼°æŒ‡æ ‡**ï¼šé…ç½®è¯„ä¼°æŒ‡æ ‡[m
[32m+[m
[32m+[m[32m4. **è®­ç»ƒé…ç½®**ï¼šè®¾ç½®å…¨é¢çš„ TrainingArguments å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡è°ƒåº¦ã€æ‰¹æ¬¡å¤§å°ã€æ··åˆç²¾åº¦è®­ç»ƒç­‰[m
[32m+[m
[32m+[m[32m5. **æ—¥å¿—è®°å½•**ï¼šé…ç½®è¯¦ç»†çš„æ—¥å¿—è®°å½•ç³»ç»Ÿï¼Œä¾¿äºç›‘æ§è®­ç»ƒè¿‡ç¨‹[m
[32m+[m
[32m+[m[32m6. **æ£€æŸ¥ç‚¹ç®¡ç†**ï¼šæ”¯æŒä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œä¿å­˜æœ€ä½³æ¨¡å‹[m
[32m+[m
[32m+[m[32m7. **è¶…å‚æ•°æœç´¢**ï¼šå¯ä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–é…ç½®[m
[32m+[m
[32m+[m[32m8. **ä¼˜åŒ–å™¨é€‰æ‹©**ï¼šåŒ…å« Apollo å’Œ Schedule-Free ç­‰å…ˆè¿›ä¼˜åŒ–å™¨é…ç½®[m
[32m+[m
[32m+[m[32m9. **å›è°ƒå‡½æ•°**ï¼šå®ç°è‡ªå®šä¹‰å›è°ƒå‡½æ•°ï¼Œæ‰©å±•è®­ç»ƒåŠŸèƒ½[m
[32m+[m
[32m+[m[32m10. **è¯„ä¼°ä¸æ¨ç†**ï¼šåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹å¹¶å±•ç¤ºç®€å•æ¨ç†ç¤ºä¾‹[m
[32m+[m
[32m+[m[32m    TrainingArgumentså‚æ•°ä¿¡æ¯ï¼šhttps://huggingface.co/docs/transformers/v4.57.1/en/main_classes/trainer#transformers.TrainingArguments[m
[32m+[m
[32m+[m[32m```python[m
[32m+[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Evaluate[m
[32m+[m
[32m+[m[32må…¸å‹çš„æœºå™¨å­¦ä¹ æµç¨‹åŒ…å«å¤šä¸ªå¯è¯„ä¼°çš„æ–¹é¢ï¼Œè€Œé’ˆå¯¹æ¯ä¸ªæ–¹é¢ï¼ŒEvaluate éƒ½æä¾›äº†ä¸€ä¸ªå·¥å…·ï¼š[m
[32m+[m[32m**æŒ‡æ ‡ï¼ˆMetricï¼‰** ï¼šæŒ‡æ ‡ç”¨äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œé€šå¸¸åŒ…å«æ¨¡å‹çš„é¢„æµ‹ç»“æœä»¥åŠä¸€äº›çœŸå®æ ‡ç­¾ã€‚[evaluate-metricï¼ˆè¯„ä¼°æŒ‡æ ‡ï¼‰ --- evaluate-metric (Evaluate Metric)](https://huggingface.co/evaluate-metric)[m
[32m+[m
[32m+[m[32m**æ¯”è¾ƒï¼ˆComparisonï¼‰** ï¼šæ¯”è¾ƒç”¨äºæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡æ¯”è¾ƒå®ƒä»¬çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ï¼Œå¹¶è®¡ç®—å®ƒä»¬çš„å»åˆåº¦æ¥å®ç°ã€‚[è¯„ä¼°æ¯”è¾ƒï¼ˆè¯„ä¼°æ¯”è¾ƒï¼‰ --- evaluate-comparison (Evaluate Comparison)](https://huggingface.co/evaluate-comparison)[m
[32m+[m
[32m+[m[32m**æµ‹é‡ï¼ˆMeasurementï¼‰** ï¼šæ•°æ®é›†ä¸åŸºäºè¯¥æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åŒç­‰é‡è¦ã€‚é€šè¿‡æµ‹é‡ï¼Œå¯ä»¥ç ”ç©¶æ•°æ®é›†çš„å±æ€§ã€‚[evaluate-measurement (Evaluate Measurement)](https://huggingface.co/evaluate-measurement)[m
[32m+[m
[32m+[m[32m```python[m
[32m+[m[32m"""[m
[32m+[m[32mæ­¤è„šæœ¬å±•ç¤ºäº† Hugging Face Evaluate åº“çš„ä¸»è¦åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š[m
[32m+[m[32m- åŠ è½½å’Œä½¿ç”¨å„ç§è¯„ä¼°æŒ‡æ ‡[m
[32m+[m[32m- ç»„åˆå¤šä¸ªæŒ‡æ ‡[m
[32m+[m[32m- åˆ†å¸ƒå¼è¯„ä¼°æ”¯æŒ[m
[32m+[m[32m- ä¸æ¨¡å‹è®­ç»ƒæ¡†æ¶é›†æˆ[m
[32m+[m[32m- ç»“æœå¯è§†åŒ–å’Œåˆ†äº«[m
[32m+[m[32m"""[m
[32m+[m
[32m+[m[32mimport numpy as np[m
[32m+[m[32mimport evaluate[m
[32m+[m[32mfrom evaluate import evaluator[m
[32m+[m[32mfrom evaluate.visualization import radar_plot[m
[32m+[m[32mfrom transformers import pipeline[m
[32m+[m[32mfrom datasets import load_dataset[m
[32m+[m
[32m+[m[32m# =